# -*- coding: utf-8 -*-
"""B19CSE081_B19CSE082_B19CSE106

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OzpJn8vqkghYZb56Hxjx3AlMh7Io4HLq
"""



import numpy as np
import pandas as pd
import re
import nltk



"""Preprocessing"""

df = pd.read_csv('training.csv',encoding="ISO-8859-1",names=['target','id','date','flag','user','text'])
df.head()

df.shape[0]

df.tail()

df.describe()

df.isnull().sum()

correlation_plot=df.corr()
print(correlation_plot)

df['target'].value_counts().plot.bar()

df['target'].value_counts()

df=df.drop("date",axis=1)
df=df.drop("id",axis=1)
df=df.drop("user",axis=1)
df=df.drop("flag",axis=1)
df.head()

df["text"] = df["text"].str.lower()

df.text = df.text.str.replace("  "," ")

df.text=df.text.str.replace('-'," ")

def remove_url(text):
    url_pattern = re.compile(r'https?://\S+|www\.\S+')
    return url_pattern.sub(r'', text)

for i in range(df.shape[0]):
  df.at[i,'text']=remove_url(df.at[i,'text'])

df["text"]=df["text"].str.replace('\d+','')

import string
Premove = string.punctuation
def remove_pun(text):
    return text.translate(str.maketrans('', '', Premove))
df["text"] = df["text"].apply(lambda text: remove_pun(text))

from spellchecker import SpellChecker

spell = SpellChecker()
def correct_spellings(text):
    corrected_text = []
    misspelled_words = spell.unknown(text.split())
    for word in text.split():
        if word in misspelled_words:
            corrected_text.append(spell.correction(word))
        else:
            corrected_text.append(word)
    return " ".join(corrected_text)

df[u'text'] = df[u'text'].astype(str)
df[u'text'] = df[u'text'].apply(lambda x:correct_spellings(x))

import matplotlib.pyplot as plt
from wordcloud import WordCloud, STOPWORDS
real = df['text'].values 
wordcloud = WordCloud().generate(str(real))
plt.imshow(wordcloud)
plt.axis("off")
plt.show()

x=df['text']
y=df['target']

x

"""Vectorizer"""

from sklearn.feature_extraction.text import TfidfVectorizer
tfidf_vectorizer = TfidfVectorizer()
x = tfidf_vectorizer.fit_transform(x)

"""Cross Validation"""

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=.2)

from sklearn.naive_bayes import BernoulliNB
bnb = BernoulliNB()
from sklearn.model_selection import cross_val_score
cv_scores = cross_val_score(bnb, x_train, y_train,cv=5, scoring="accuracy")
cv_scores

cv_scores.mean()

from sklearn.linear_model import LogisticRegression
lgr=LogisticRegression(max_iter=1500)
from sklearn.model_selection import cross_val_score
cv_scores = cross_val_score(lgr, x_train, y_train,cv=5, scoring="accuracy")
cv_scores

cv_scores.mean()

"""Classifiers"""

from sklearn.naive_bayes import BernoulliNB
bnb = BernoulliNB()
bnb.fit(x_train,y_train)
y_pred=bnb.predict(x_test)
from sklearn.metrics import accuracy_score
print(accuracy_score(y_test,y_pred))

from sklearn.neural_network import MLPClassifier
mlpcl = MLPClassifier(max_iter=300).fit(x_train, y_train)
y_prediction=mlpcl.predict(x_test)
print(accuracy_score(y_test,y_prediction))

from sklearn.linear_model import LogisticRegression
lgr = LogisticRegression(max_iter=1500).fit(x_train, y_train)
y_prediction=lgr.predict(x_test)
print(accuracy_score(y_test,y_prediction))

from sklearn.svm import LinearSVC
svc = LinearSVC().fit(x_train, y_train)
y_predict=svc.predict(x_test)
print(accuracy_score(y_test,y_predict))

x1=x
y1=y

x1.shape

from sklearn.model_selection import train_test_split
x_train1,x_test1,y_train1,y_test1=train_test_split(x1,y1,test_size=.2)

"""Standardization"""

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler(with_mean=False)
x_train1=scaler.fit_transform(x_train1)
x_test1 = scaler.fit_transform(x_test1)

"""Dimensionality Reduction Using PCA"""

from sklearn.decomposition import TruncatedSVD
svd = TruncatedSVD()
svd.fit_transform(x_train1)

svd.explained_variance_ratio_

svd.n_components

x_train1.shape

y_train1.shape

from sklearn.linear_model import LogisticRegression
lgr = LogisticRegression(max_iter=1500)
lgr.fit(x_train1,y_train1)

lgr.score(x_test1,y_test1)

from sklearn.naive_bayes import BernoulliNB
bnb = BernoulliNB()
bnb.fit(x_train1,y_train1)
y_pred=bnb.predict(x_test1)
from sklearn.metrics import accuracy_score
print(accuracy_score(y_test1,y_pred))

from sklearn.svm import LinearSVC
svc = LinearSVC(max_iter=1500).fit(x_train1, y_train1)
y_predict=svc.predict(x_test1)

from sklearn.metrics import accuracy_score
print(accuracy_score(y_test1,y_predict))